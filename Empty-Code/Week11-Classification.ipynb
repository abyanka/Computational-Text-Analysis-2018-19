{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, logging\n",
    "# the model is organized like this: word = embeddings\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('../resources/small-embeddings.txt', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk, string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "stop_word_list = stopwords.words('english')\n",
    "\n",
    "# input should be a string\n",
    "def text_embedding(text):\n",
    "    \n",
    "    #it depends if the words have been lowercased or not\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = nltk.word_tokenize(text)\n",
    "        \n",
    "    text = [token for token in text if token not in exclude and token.isalpha()]\n",
    "    \n",
    "    text = [token for token in text if token not in stop_word_list]\n",
    "\n",
    "    article_embedd = []\n",
    "    \n",
    "    for word in text:\n",
    "            try:\n",
    "                embed_word = model[word]\n",
    "                article_embedd.append(embed_word)\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "    avg = [float(sum(col))/len(col) for col in zip(*article_embedd)]\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YELP product reviews dataset\n",
    "\n",
    "import codecs\n",
    "\n",
    "sentiment_dataset = codecs.open(\"../datasets/yelp-test.csv\",\"r\",\"utf-8\").read().strip().split(\"\\n\")\n",
    "\n",
    "print (sentiment_dataset[1])\n",
    "print (\" \")\n",
    "print (sentiment_dataset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first, we define two folders, \"corpus\" - with the text and \"labels\", with the labels\n",
    "\n",
    "corpus = []\n",
    "labels = []\n",
    "\n",
    "# be careful with this, the dataset is huge!\n",
    "#for line in sentiment_dataset:\n",
    "for line in sentiment_dataset[:10000]:\n",
    "    text = line.split(\",\")[1].replace('\"','')\n",
    "    label = line.split(\",\")[0].replace('\"','').replace(\"1\",\"-1\").replace(\"2\",\"1\")\n",
    "    \n",
    "    emb_text = text_embedding(text)\n",
    "    if len(emb_text) > 0:\n",
    "        corpus.append(emb_text)\n",
    "        labels.append(label)\n",
    "    \n",
    "print (\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# we use np array as they are more efficient\n",
    "X = np.array(corpus)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here's the documentation: http://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "final_f1 = []\n",
    "\n",
    "kf_total = cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True)\n",
    "\n",
    "for train, test in kf_total:\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    final_C = 1\n",
    "    classifier = GaussianNB().fit(X_train , y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print (precision_recall_fscore_support(y_test, y_pred, average=\"macro\"))\n",
    "    f1_score = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")[2]\n",
    "    final_f1.append(f1_score)\n",
    "print (\" \")\n",
    "print (sum(final_f1)/len(final_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here's the documentation: http://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.SVC(kernel = \"linear\", C=1) \n",
    "\n",
    "final_f1 = []\n",
    "\n",
    "kf_total = cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True)\n",
    "\n",
    "for train, test in kf_total:\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    final_C = 1\n",
    "    classifier = SVM.fit(X_train , y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print (precision_recall_fscore_support(y_test, y_pred, average=\"macro\"))\n",
    "    f1_score = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")[2]\n",
    "    final_f1.append(f1_score)\n",
    "print (\" \")\n",
    "print (sum(final_f1)/len(final_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "final_f1 = []\n",
    "# we set that we do 10 fold cross validation\n",
    "kf_total = cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True)\n",
    "# for each of the 10 round\n",
    "for train, test in kf_total:\n",
    "    # we define training and test embeddings and labels\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    # we train the classifier (using 50 neighbors, but you can change that)\n",
    "    # we train on the training set, using embeddings and labels\n",
    "    classifier = KNeighborsClassifier(n_neighbors=50).fit(X_train, y_train) \n",
    "    \n",
    "    # then we test it on the test set, we provide the embeddings and we make the classifier predict the labels\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # then we compare the prediction with the true test-labels using precision, recall and f1 (ignore the last None column)\n",
    "    print (precision_recall_fscore_support(y_test, y_pred, average=\"macro\"))\n",
    "    f1_score = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")[2]\n",
    "    final_f1.append(f1_score)\n",
    "    \n",
    "print (\" \")\n",
    "print (sum(final_f1)/len(final_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homework 2 - nearest centroid\n",
    "\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "\n",
    "final_f1 = []\n",
    "\n",
    "kf_total = cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True)\n",
    "for train, test in kf_total:\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    classifier = NearestCentroid().fit(X_train, y_train) \n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print (precision_recall_fscore_support(y_test, y_pred, average=\"macro\"))\n",
    "    f1_score = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")[2]\n",
    "    final_f1.append(f1_score)\n",
    "print (\" \")\n",
    "print (sum(final_f1)/len(final_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
