{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# homework from previous day - we can discuss about them together after class or in the meeting-hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1) how to write a for loop?\n",
    "\n",
    " 2) write a if statement\n",
    "\n",
    " 3) which python objects have we learnt so far?\n",
    "\n",
    " 4) write a list\n",
    "\n",
    " 5) write a dictionary\n",
    "\n",
    " 6) which libraries did we use so far?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open the new dataset\n",
    "\n",
    "import codecs\n",
    "\n",
    "# or \\r\\n\n",
    "\n",
    "dataset = codecs.open(\"dataset.tsv\", \"r\", \"utf-8\").read().strip().split(\"\\n\")\n",
    "\n",
    "# if you want to create a similar dataset -> https://github.com/fedenanni/collecting-news-from-the-internet-archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "let's break down what we are doing here\n",
    "\n",
    "1) we define a variable called \"dataset\"\n",
    "\n",
    "2) we use a library - called \"codecs\" for open it\n",
    "\n",
    "3) we open the file\n",
    "\n",
    "4) we give the path to the file, we say that it's in \"read\" mode (not write mode), and the encoding\n",
    "\n",
    "5) we read it\n",
    "\n",
    "6) we remove empty lines at the end (with strip)\n",
    "\n",
    "7) we split it with the breakline - if the file is created on windows you should use \"\\r\\n\"  <-- as in \"return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11176\n",
      "date \ttitle \ttopic \tcontent\n"
     ]
    }
   ],
   "source": [
    "# now - what type of objects is \"dataset\" ?\n",
    "\n",
    "\n",
    "# what is the length of \"dataset\" ?\n",
    "\n",
    "print (len(dataset))\n",
    "\n",
    "\n",
    "# how do we print a sample of \"dataset\" ?\n",
    "\n",
    "print (dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('news', 2726), ('usa', 1860), ('uk', 1123), ('op-edge', 1098), ('in-motion', 920), ('business', 883), ('viral', 850), ('sport', 838), ('politics', 509), ('shows', 356), ('on-air', 9), ('topic ', 1), ('about-us', 1), ('360', 1), ('business-projects', 1)]\n"
     ]
    }
   ],
   "source": [
    "# how to count the number of topics?\n",
    "\n",
    "#first, we create a list\n",
    "\n",
    "topics = []\n",
    "\n",
    "# then ,we write a for-loop\n",
    "\n",
    "for line in dataset:\n",
    "    topic = line.split(\"\\t\")[2]\n",
    "    topics.append(topic)\n",
    "    \n",
    "from collections import Counter\n",
    "\n",
    "print (Counter(topics).most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('news', 2726), ('usa', 1860), ('uk', 1123), ('op-edge', 1098), ('in-motion', 920), ('business', 883), ('viral', 850), ('sport', 838), ('politics', 509), ('shows', 356), ('on-air', 9), ('topic ', 1), ('about-us', 1), ('360', 1), ('business-projects', 1)]\n"
     ]
    }
   ],
   "source": [
    "# a different way of doing the same thing\n",
    "\n",
    "topics = [line.split(\"\\t\")[2] for line in dataset]\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "print (Counter(topics).most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READ MORE:¬†Iceland hearts broken as France wins 5-2 to reach Euro 2016 semi-final In a tournament plagued with violence and disruption, it was a moral victory for Iceland who showed an example of true sportsmanship and team discipline. Props to Iceland. No can take away what you've done. I've never seen so much heart. DAMN Fans took to Twitter in their droves to commend the team and their supporters for their classy performance that many credited as the highlight of Euro-2016 so far. Well done Iceland. Redefined concept of 'teamwork' and taught the world you don't have to accept imposed limits. pic.twitter.com/aGVo1dfeRa No one was more surprised than Icelanders that their team made it so far, and no one was more overjoyed. ‚Ç¨14m in prize money.10% of the population travelled.More volcanoes than footballers.It's been a blast, Iceland! pic.twitter.com/yaoNDwyQmg One last clap for the team that knocked the motherland of football England out of the tournament, despite having more volcanoes than professional football players. The last clap. üëèThanks for the memories, Iceland!  #FRAISL#ISL (via @Chandelaas)  pic.twitter.com/Fq2fNB0H2i The players, the fans, the president‚Ä¶¬†they have really put their country on the map for the rest of the world. #Iceland president refused his VIP seat to watch the game and sat with the supporters. Great spirit. Great nation pic.twitter.com/EIh6KnCGgW It wouldn't be surprising if Iceland sees a spike in tourism this year. Massive Respect To This Iceland Team pic.twitter.com/kvRQX9iUTp One last clap for Iceland and its historic run to the EURO quarterfinals. https://t.co/g5bsNV77sT France vs Iceland. Here we go. https://t.co/1qgIH3rLa8  \n"
     ]
    }
   ],
   "source": [
    "# let's start with some real NLP\n",
    "\n",
    "# let's focus on a specific article, for example\n",
    "\n",
    "article = dataset[50].split(\"\\t\")[3]\n",
    "print (article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/federiconanni/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk # --> documentation: http://www.nltk.org/\n",
    "\n",
    "# you will also need this\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (type(article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "20\n",
      "['READ MORE:\\xa0Iceland hearts broken as France wins 5-2 to reach Euro 2016 semi-final In a tournament plagued with violence and disruption, it was a moral victory for Iceland who showed an example of true sportsmanship and team discipline.', 'Props to Iceland.', \"No can take away what you've done.\", \"I've never seen so much heart.\", 'DAMN Fans took to Twitter in their droves to commend the team and their supporters for their classy performance that many credited as the highlight of Euro-2016 so far.', 'Well done Iceland.', \"Redefined concept of 'teamwork' and taught the world you don't have to accept imposed limits.\", 'pic.twitter.com/aGVo1dfeRa No one was more surprised than Icelanders that their team made it so far, and no one was more overjoyed.', \"‚Ç¨14m in prize money.10% of the population travelled.More volcanoes than footballers.It's been a blast, Iceland!\", 'pic.twitter.com/yaoNDwyQmg One last clap for the team that knocked the motherland of football England out of the tournament, despite having more volcanoes than professional football players.', 'The last clap.', 'üëèThanks for the memories, Iceland!', '#FRAISL#ISL (via @Chandelaas)  pic.twitter.com/Fq2fNB0H2i The players, the fans, the president‚Ä¶\\xa0they have really put their country on the map for the rest of the world.', '#Iceland president refused his VIP seat to watch the game and sat with the supporters.', 'Great spirit.', \"Great nation pic.twitter.com/EIh6KnCGgW It wouldn't be surprising if Iceland sees a spike in tourism this year.\", 'Massive Respect To This Iceland Team pic.twitter.com/kvRQX9iUTp One last clap for Iceland and its historic run to the EURO quarterfinals.', 'https://t.co/g5bsNV77sT France vs Iceland.', 'Here we go.', 'https://t.co/1qgIH3rLa8']\n"
     ]
    }
   ],
   "source": [
    "# we start by dividing the text into sentences\n",
    "sentences = nltk.sent_tokenize(article) # <-- documentation for this command: http://www.nltk.org/_modules/nltk/tokenize.html\n",
    "\n",
    "# for checking what you're getting back from a library, run these commands\n",
    "print (type(sentences))\n",
    "print (len(sentences))\n",
    "print (sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAMN Fans took to Twitter in their droves to commend the team and their supporters for their classy performance that many credited as the highlight of Euro-2016 so far.\n"
     ]
    }
   ],
   "source": [
    "# let us consider a single sentence - how do we do that? ## use the 5th sentence\n",
    "\n",
    "sentence = sentences[4]\n",
    "print (sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DAMN', 'Fans', 'took', 'to', 'Twitter', 'in', 'their', 'droves', 'to', 'commend', 'the', 'team', 'and', 'their', 'supporters', 'for', 'their', 'classy', 'performance', 'that', 'many', 'credited', 'as', 'the', 'highlight', 'of', 'Euro-2016', 'so', 'far', '.']\n"
     ]
    }
   ],
   "source": [
    "# let's divide the sentence in tokens (aka single words)\n",
    "tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "\n",
    "print (tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['damn', 'fans', 'took', 'to', 'twitter', 'in', 'their', 'droves', 'to', 'commend', 'the', 'team', 'and', 'their', 'supporters', 'for', 'their', 'classy', 'performance', 'that', 'many', 'credited', 'as', 'the', 'highlight', 'of', 'euro-2016', 'so', 'far', '.']\n"
     ]
    }
   ],
   "source": [
    "# lower-casing the sentence\n",
    "without_capital_letters = [word.lower() for word in tokenized_sentence]\n",
    "\n",
    "print (without_capital_letters)\n",
    "\n",
    "# homework: write a for-loop for doing the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n"
     ]
    }
   ],
   "source": [
    "# removing stopwords\n",
    "\n",
    "# homework: download stopwords <- google it out\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# what is \"stop\" ?\n",
    "\n",
    "print (stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['damn', 'fans', 'took', 'twitter', 'droves', 'commend', 'team', 'supporters', 'classy', 'performance', 'many', 'credited', 'highlight', 'euro-2016', 'far', '.']\n"
     ]
    }
   ],
   "source": [
    "without_stop_words = [word for word in without_capital_letters if word not in stop]\n",
    "\n",
    "print (without_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['damn', 'fans', 'took', 'twitter', 'droves', 'commend', 'team', 'supporters', 'classy', 'performance', 'many', 'credited', 'highlight', 'euro-2016', 'far']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "\n",
    "# homework: how do we exclude punctuation?, hint: use exclude, from the previous line\n",
    "\n",
    "without_punct = [word for word in without_stop_words if word not in exclude]\n",
    "\n",
    "print (without_punct)\n",
    "\n",
    "# homework: remove numbers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
