{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim, logging\n",
    "# the model is organized like this: word = embeddings\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('resources/small-embeddings.txt', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk, string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "stop_word_list = stopwords.words('english')\n",
    "\n",
    "# input should be a string\n",
    "def text_embedding(text):\n",
    "    \n",
    "    #it depends if the words have been lowercased or not\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = nltk.word_tokenize(text)\n",
    "        \n",
    "    text = [token for token in text if token not in exclude and token.isalpha()]\n",
    "    \n",
    "    text = [token for token in text if token not in stop_word_list]\n",
    "\n",
    "    article_embedd = []\n",
    "    \n",
    "    for word in text:\n",
    "            try:\n",
    "                embed_word = small_model[word]\n",
    "                article_embedd.append(embed_word)\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "    avg = [float(sum(col))/len(col) for col in zip(*article_embedd)]\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.26903926208615303, 0.7144050151109695, 0.6478350050747395, 0.3210650235414505, 0.07041849289089441, -0.021145001519471407, -0.7754549980163574, -0.2608862593770027, -0.2335975021123886, -0.44401000440120697, -0.7981760036200285, -0.2174225002527237, -0.2587737590074539, 0.020651994738727808, 0.16106024757027626, 0.11651949770748615, -0.40395849477499723, -0.11410426755901426, 0.19817999750375748, -0.18172174505889416, -0.09501974750310183, 0.13451825641095638, 0.24662524834275246, -0.6156899929046631, 0.17309998720884323, -2.1071474701166153, 0.201797503978014, 0.0012424960732460022, -0.7112424969673157, -0.06578348483890295, 1.8628499507904053, 0.3978800028562546, -1.0788562297821045, -0.5919300131499767, -0.5450749918818474, -1.0065224766731262, -0.4167025089263916, 0.18753925105556846, -0.6404455121737556, -0.8506049998104572, -0.3560800105333328, 0.3043750002980232, -0.3289024978876114, -0.748709999024868, 0.187304999679327, 0.5087025091052055, -0.7147175222635269, 0.20657499879598618, -0.3577454970218241, 0.6135782618075609]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Barack Obama was president of the USA\"\n",
    "\n",
    "embed_sentence = text_embedding(sentence)\n",
    "print (embed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1\",\"Last summer I had an appointment to get new tires and had to wait a super long time. I also went in this week for them to fix a minor problem with a tire they put on. They \\\"\"fixed\\\"\" it for free, and the very next morning I had the same issue. I called to complain, and the \\\"\"manager\\\"\" didn't even apologize!!! So frustrated. Never going back.  They seem overpriced, too.\"\n",
      " \n",
      "\"2\",\"Friendly staff, same starbucks fair you get anywhere else.  Sometimes the lines can get long.\"\n"
     ]
    }
   ],
   "source": [
    "# YELP product reviews dataset\n",
    "\n",
    "import codecs\n",
    "\n",
    "sentiment_dataset = codecs.open(\"datasets/yelp-test.csv\",\"r\",\"utf-8\").read().strip().split(\"\\n\")\n",
    "\n",
    "print (sentiment_dataset[1])\n",
    "print (\" \")\n",
    "print (sentiment_dataset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we define two folders, \"corpus\" - with the text and \"labels\", with the labels\n",
    "\n",
    "corpus = []\n",
    "labels = []\n",
    "\n",
    "# be careful with this, the dataset is huge!\n",
    "#for line in sentiment_dataset:\n",
    "for line in sentiment_dataset[:1000]:\n",
    "    text = line.split(\",\")[1].replace('\"','')\n",
    "    label = line.split(\",\")[0].replace('\"','').replace(\"1\",\"-1\").replace(\"2\",\"1\")\n",
    "    \n",
    "    corpus.append(text)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.0\n",
      "3.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# AFINN Dictionary for Sentiment Analysis: https://github.com/fnielsen/afinn\n",
    "#!pip install afinn\n",
    "\n",
    "from afinn import Afinn\n",
    "\n",
    "afinn = Afinn()\n",
    "\n",
    "print (afinn.score(\"This is bad fake news\"))\n",
    "\n",
    "print (afinn.score(\"An exam in the mid of December? Oh, that's great!\"))\n",
    "\n",
    "print (afinn.score(\"That movie is horrible and beautiful at the same time\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "for review in corpus:\n",
    "    score = afinn.score(review)\n",
    "    \n",
    "    if score < 0.0:\n",
    "        pred.append(\"-1\")\n",
    "    else:\n",
    "        pred.append(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7065650739683889, 0.6226429452570531, 0.5722449661809613, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "print (precision_recall_fscore_support(labels, pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework: Instead of taking the entire text, you can process it (e.g., remove the POS tagger, keep stopwords, etc) and see if you can improve the performance of the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready!\n"
     ]
    }
   ],
   "source": [
    "# first, we define two folders, \"corpus\" - with the text and \"labels\", with the labels\n",
    "\n",
    "corpus = []\n",
    "labels = []\n",
    "\n",
    "# be careful with this, the dataset is huge!\n",
    "#for line in sentiment_dataset:\n",
    "for line in sentiment_dataset[:10000]: #<-- by adding more training data performance will improve (i hope!)\n",
    "# however, it'll use lots of memory ;-)\n",
    "    label = line.split(\",\")[0].replace('\"','').replace(\"1\",\"-1\").replace(\"2\",\"1\")\n",
    "    text = line.split(\",\")[1].replace('\"','')\n",
    "    \n",
    "    doc_emb = text_embedding(text)\n",
    "    \n",
    "    if len(doc_emb)>0:\n",
    "        corpus.append(doc_emb)\n",
    "        labels.append(label)\n",
    "print (\"ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(corpus)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6720529412238131, 0.6729801351296678, 0.6715878607412213, None)\n",
      "(0.6545087265675501, 0.655017267376818, 0.6525417918573935, None)\n",
      "(0.649571903557524, 0.6493384892261297, 0.6455733973392903, None)\n",
      "(0.6566430626960261, 0.6574333601436383, 0.6565523747632627, None)\n",
      "(0.6638046116504854, 0.6644873138511784, 0.6621883790862353, None)\n",
      "(0.6361441742826437, 0.6368808241325241, 0.6356771212636145, None)\n",
      "(0.623965900124458, 0.6238108004907099, 0.6238781582284656, None)\n",
      "(0.6502592349938932, 0.6509257679527489, 0.6503011685156095, None)\n",
      "(0.6402366432614981, 0.6406809817446197, 0.6381291824265348, None)\n",
      "(0.6645062331152557, 0.6642456148902809, 0.6602929292929294, None)\n",
      " \n",
      "0.6496722363514558\n"
     ]
    }
   ],
   "source": [
    "#here's the documentation: http://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "final_f1 = []\n",
    "\n",
    "kf_total = cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True)\n",
    "\n",
    "for train, test in kf_total:\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    final_C = 1\n",
    "    classifier = GaussianNB().fit(X_train , y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print (precision_recall_fscore_support(y_test, y_pred, average=\"macro\"))\n",
    "    f1_score = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")[2]\n",
    "    final_f1.append(f1_score)\n",
    "print (\" \")\n",
    "print (sum(final_f1)/len(final_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.671067221067221, 0.6697799085649553, 0.670148981083056, None)\n",
      "(0.7010244758855726, 0.6972493798336494, 0.6979189111633735, None)\n",
      "(0.6934955827776228, 0.6882995281871687, 0.6888746414090257, None)\n",
      "(0.6806154608269348, 0.6718053084403715, 0.6717363672937087, None)\n",
      "(0.6881176599993231, 0.6806303671386905, 0.6809388149435847, None)\n",
      "(0.7136651878484019, 0.710507608439559, 0.7112334657706709, None)\n",
      "(0.6650283301484516, 0.6606709075694428, 0.6609811165845649, None)\n",
      "(0.6657761226252159, 0.6622003135993241, 0.6625912687314119, None)\n",
      "(0.6847393267651889, 0.6828076888704737, 0.6832968790806999, None)\n",
      "(0.6924376299376299, 0.6864981679624981, 0.6870374481941977, None)\n",
      " \n",
      "0.6814757894254294\n"
     ]
    }
   ],
   "source": [
    "#here's the documentation: http://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.SVC(kernel = \"linear\", C=1) \n",
    "\n",
    "final_f1 = []\n",
    "\n",
    "kf_total = cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True)\n",
    "\n",
    "for train, test in kf_total:\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    final_C = 1\n",
    "    classifier = SVM.fit(X_train , y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print (precision_recall_fscore_support(y_test, y_pred, average=\"macro\"))\n",
    "    f1_score = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")[2]\n",
    "    final_f1.append(f1_score)\n",
    "print (\" \")\n",
    "print (sum(final_f1)/len(final_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
